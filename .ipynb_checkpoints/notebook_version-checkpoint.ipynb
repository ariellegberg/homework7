{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f1876d9-77f4-4570-8201-961de429494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Define sentiment words\n",
    "\n",
    "# Love\n",
    "love_words = [\"love\", \"joy\", \"enchanting\", \"captivating\", \"beautiful\", \"romance\", \"happiness\", \"healing\", \"connection\",\n",
    "              \"adventure\", \"shiny\", \"sweet\", \"nice\", \"light\", \"blue\", \"lightblue\", \"yellow\", \"pink\", \"gold\", \"green\",\n",
    "              \"purple\", \"courage\", \"faith\", \"passion\", \"amazing\", \"new\", \"wonderful\"]\n",
    "\n",
    "# Heartbreak\n",
    "heartbreak_words = [\"upset\", \"wait\", \"hate\", \"dislike\", \"scared\", \"angry\", \"confused\", \"stupid\", \"fear\", \"sadness\",\n",
    "                    \"doubts\", \"doubt\", \"hurt\", \"pain\", \"heartbreak\", \"dark\", \"tragic\", \"lonely\", \"loneliness\",\n",
    "                    \"loathing\", \"devastating\", \"devastated\", \"solitary\", \"cry\", \"cold\", \"tears\", \"teardrops\",\n",
    "                    \"turmoil\", \"demons\", \"terror\", \"terrors\", \"black\", \"reputation\", \"brown\", \"darkgreen\", \"grey\",\n",
    "                    \"loss\", \"bye\"]\n",
    "\n",
    "# Optimism\n",
    "optimism_words = [\"finally\", \"relief\", \"hope\", \"dreams\", \"wonderment\", \"wonder\", \"wonderful\", \"smile\", \"intrigue\",\n",
    "                  \"happy\", \"sunshine\", \"bright\", \"uplifting\", \"positive\", \"cheerful\", \"optimistic\", \"inspiration\",\n",
    "                  \"excitement\", \"vibrant\"]\n",
    "\n",
    "# Anger\n",
    "anger_words = [\"angry\", \"hate\", \"mad\", \"outraged\", \"resentment\", \"fury\", \"dislike\", \"bad\", \"unsafe\", \"gross\",\n",
    "               \"loathing\", \"loathe\", \"goodbye\", \"liar\", \"lies\", \"lie\", \"rage\", \"bitter\", \"hostile\", \"vindictive\",\n",
    "               \"outrageous\", \"provoked\", \"enraged\", \"irritated\", \"furious\", \"infuriated\"]\n",
    "\n",
    "# Reflection\n",
    "reflection_words = [\"loss\", \"bye\", \"enchanting\", \"demons\", \"terror\", \"terrors\", \"black\", \"reputation\", \"brown\",\n",
    "                    \"darkgreen\", \"grey\", \"memories\", \"nostalgia\", \"contemplate\", \"introspection\", \"ponder\",\n",
    "                    \"reminisce\", \"meditate\", \"introspective\", \"thoughtful\", \"reflective\"]\n",
    "\n",
    "\n",
    "## Define sentiment analysis function to calculate percentages\n",
    "\n",
    "def calculate_sentiment_percentages(text):\n",
    "    words = text.lower().split()\n",
    "    total_count = len(words)\n",
    "\n",
    "    love_count = sum(word in love_words for word in words)\n",
    "    heartbreak_count = sum(word in heartbreak_words for word in words)\n",
    "    optimism_count = sum(word in optimism_words for word in words)\n",
    "    anger_count = sum(word in anger_words for word in words)\n",
    "    reflection_count = sum(word in reflection_words for word in words)\n",
    "\n",
    "    love_percentage = love_count / total_count * 100\n",
    "    heartbreak_percentage = heartbreak_count / total_count * 100\n",
    "    optimism_percentage = optimism_count / total_count * 100\n",
    "    anger_percentage = anger_count / total_count * 100\n",
    "    reflection_percentage = reflection_count / total_count * 100\n",
    "\n",
    "    return love_percentage, heartbreak_percentage, optimism_percentage, anger_percentage, reflection_percentage\n",
    "\n",
    "def df():\n",
    "    df = pd.read_csv(\"preprocessed_data.csv\")\n",
    "\n",
    "   # Apply sentiment analysis to the prologue text\n",
    "    df['Love'], df['Heartbreak'], df['Optimism'], df['Anger'], df['Reflection'] = zip(\n",
    "        *df['Prologue Text'].apply(calculate_sentiment_percentages))\n",
    "\n",
    "    # Normalize percentages so each sentiment category's bar extends to the same height (representing 100%)\n",
    "    df['Total'] = df[['Love', 'Heartbreak', 'Optimism', 'Anger', 'Reflection']].sum(axis=1)\n",
    "    df['Love'] = (df['Love'] / df['Total']) * 100\n",
    "    df['Heartbreak'] = (df['Heartbreak'] / df['Total']) * 100\n",
    "    df['Optimism'] = (df['Optimism'] / df['Total']) * 100\n",
    "    df['Anger'] =  (df['Anger'] / df['Total']) * 100\n",
    "    df['Reflection'] = (df['Reflection'] /df['Total']) * 100\n",
    "    df['Total'] = 100\n",
    "    return df\n",
    "\n",
    "df = df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e5b5c4-063f-48b3-b5dc-aa2a9f0e6d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Prologue Text</th>\n",
       "      <th>Date released</th>\n",
       "      <th>Color</th>\n",
       "      <th>Total Album Sales (In Millions)</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Avg Sentence Length</th>\n",
       "      <th>Avg Word Length</th>\n",
       "      <th>Love</th>\n",
       "      <th>Heartbreak</th>\n",
       "      <th>Optimism</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Reflection</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fearless</td>\n",
       "      <td>album called fearless guess id like clarify ch...</td>\n",
       "      <td>11/08/2008</td>\n",
       "      <td>gold</td>\n",
       "      <td>10,002,500</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>5.902256</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Speak Now</td>\n",
       "      <td>speak forever hold peace words said preachers ...</td>\n",
       "      <td>10/25/2011</td>\n",
       "      <td>purple</td>\n",
       "      <td>6,437,500</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>5.134921</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red</td>\n",
       "      <td>theres old poem neruda ive always captivated o...</td>\n",
       "      <td>10/22/2012</td>\n",
       "      <td>red</td>\n",
       "      <td>7,257,500</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>5.614035</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989</td>\n",
       "      <td>songs life born reading pennsylvania december ...</td>\n",
       "      <td>10/27/2014</td>\n",
       "      <td>light blue</td>\n",
       "      <td>10,735,000</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>5.390041</td>\n",
       "      <td>70.588235</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>17.647059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reputation</td>\n",
       "      <td>heres something ive learned people think know ...</td>\n",
       "      <td>11/10/2017</td>\n",
       "      <td>black</td>\n",
       "      <td>3,710,000</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>6.120332</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Album Name                                      Prologue Text  \\\n",
       "0    Fearless  album called fearless guess id like clarify ch...   \n",
       "1   Speak Now  speak forever hold peace words said preachers ...   \n",
       "2         Red  theres old poem neruda ive always captivated o...   \n",
       "3        1989  songs life born reading pennsylvania december ...   \n",
       "4  Reputation  heres something ive learned people think know ...   \n",
       "\n",
       "  Date released       Color Total Album Sales (In Millions)  Word Count  \\\n",
       "0    11/08/2008        gold                      10,002,500         133   \n",
       "1    10/25/2011      purple                       6,437,500         252   \n",
       "2    10/22/2012         red                       7,257,500         171   \n",
       "3    10/27/2014  light blue                      10,735,000         241   \n",
       "4    11/10/2017       black                       3,710,000         241   \n",
       "\n",
       "   Avg Sentence Length  Avg Word Length       Love  Heartbreak   Optimism  \\\n",
       "0                    1         5.902256  58.333333   33.333333   0.000000   \n",
       "1                    1         5.134921  33.333333   58.333333   8.333333   \n",
       "2                    1         5.614035  73.333333    6.666667  13.333333   \n",
       "3                    1         5.390041  70.588235    5.882353  17.647059   \n",
       "4                    1         6.120332  25.000000   12.500000  37.500000   \n",
       "\n",
       "       Anger  Reflection  Total  \n",
       "0   8.333333    0.000000    100  \n",
       "1   0.000000    0.000000    100  \n",
       "2   0.000000    6.666667    100  \n",
       "3   0.000000    5.882353    100  \n",
       "4  12.500000   12.500000    100  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a9a3f-dcc6-48af-9bcf-4f5e56dfbcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
