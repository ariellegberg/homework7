{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f44a9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26df36ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Vero/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/Vero/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2ff2ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Taylor Swift Album Prologues - Sheet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e044d3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Prologue Text</th>\n",
       "      <th>Date released</th>\n",
       "      <th>Color</th>\n",
       "      <th>Total Album Sales (In Millions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fearless</td>\n",
       "      <td>This album is called \"Fearless\", and I guess I...</td>\n",
       "      <td>11/08/2008</td>\n",
       "      <td>gold</td>\n",
       "      <td>10,002,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Speak Now</td>\n",
       "      <td>Speak now or forever hold your peace,' the wor...</td>\n",
       "      <td>10/25/2011</td>\n",
       "      <td>purple</td>\n",
       "      <td>6,437,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red</td>\n",
       "      <td>There's an old poem by Neruda that I've always...</td>\n",
       "      <td>10/22/2012</td>\n",
       "      <td>red</td>\n",
       "      <td>7,257,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989</td>\n",
       "      <td>\"These songs were once about my life. They are...</td>\n",
       "      <td>10/27/2014</td>\n",
       "      <td>light blue</td>\n",
       "      <td>10,735,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reputation</td>\n",
       "      <td>Here's something I've learned about people. W...</td>\n",
       "      <td>11/10/2017</td>\n",
       "      <td>black</td>\n",
       "      <td>3,710,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lover</td>\n",
       "      <td>When I found old diaries from my childhood and...</td>\n",
       "      <td>08/23/2019</td>\n",
       "      <td>pink</td>\n",
       "      <td>2,722,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Folklore</td>\n",
       "      <td>It started with imagery. Visuals that popped i...</td>\n",
       "      <td>07/24/2020</td>\n",
       "      <td>grey</td>\n",
       "      <td>3,197,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Evermore</td>\n",
       "      <td>To put it plainly, we just couldn't stop writi...</td>\n",
       "      <td>12/11/2020</td>\n",
       "      <td>brown</td>\n",
       "      <td>1,867,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>What keeps you up at night? It's a momentary g...</td>\n",
       "      <td>10/21/2022</td>\n",
       "      <td>dark blue</td>\n",
       "      <td>3,700,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Album Name                                      Prologue Text  \\\n",
       "0    Fearless  This album is called \"Fearless\", and I guess I...   \n",
       "1   Speak Now  Speak now or forever hold your peace,' the wor...   \n",
       "2         Red  There's an old poem by Neruda that I've always...   \n",
       "3        1989  \"These songs were once about my life. They are...   \n",
       "4  Reputation   Here's something I've learned about people. W...   \n",
       "5       Lover  When I found old diaries from my childhood and...   \n",
       "6    Folklore  It started with imagery. Visuals that popped i...   \n",
       "7    Evermore  To put it plainly, we just couldn't stop writi...   \n",
       "8   Midnights  What keeps you up at night? It's a momentary g...   \n",
       "\n",
       "  Date released       Color Total Album Sales (In Millions)  \n",
       "0    11/08/2008        gold                      10,002,500  \n",
       "1    10/25/2011      purple                       6,437,500  \n",
       "2    10/22/2012         red                       7,257,500  \n",
       "3    10/27/2014  light blue                      10,735,000  \n",
       "4    11/10/2017       black                       3,710,000  \n",
       "5    08/23/2019        pink                       2,722,500  \n",
       "6    07/24/2020        grey                       3,197,500  \n",
       "7    12/11/2020       brown                       1,867,500  \n",
       "8    10/21/2022  dark blue                        3,700,000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "758f3151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 1 in column 'Prologue Text': ['T', 'F', 'I', 'I', 'T', 'F', 'I', 'T', 'F', 'L', 'T', 'F', 'F', 'F', 'I', 'F', 'I', 'A', 'I', 'I', 'N', 'O', 'T', 'I', 'I', 'L', 'T', 'T', 'B', 'Y', 'T', 'I', 'B', 'I']\n",
      "Cell 2 in column 'Prologue Text': ['S', 'I', 'I', 'S', 'I', 'R', 'I', 'S', 'B', 'I', 'I', 'W', 'I', 'W', 'I', 'W', 'T', 'I', 'T', 'E', 'I', 'T', 'I', 'D', 'T', 'I', 'T', 'T', 'I', 'T', 'T', 'T', 'I', 'W', 'I', 'W', 'M', 'B', 'I', 'S', 'O', 'S', 'I', 'I', 'T', 'T', 'B', 'I', 'I', 'L', 'T', 'P', 'S', 'T']\n",
      "Cell 3 in column 'Prologue Text': ['T', 'N', 'I', 'I', 'I', 'I', 'I', 'I', 'A', 'T', 'T', 'A', 'I', 'M', 'T', 'T', 'A', 'A', 'A', 'A', 'A', 'I', 'B', 'A', 'A', 'M', 'I', 'I', 'I', 'L', 'B']\n",
      "Cell 4 in column 'Prologue Text': ['T', 'T', 'I', 'R', 'P', 'D', 'I', 'O', 'A', 'B', 'I', 'T', 'T', 'I', 'A', 'I', 'I', 'T', 'I', 'I', 'E', 'I', 'I', 'F', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'N', 'Y', 'I', 'I', 'I', 'I', 'T', 'I', 'W', 'I', 'I', 'I', 'I', 'I', 'S', 'S', 'T', 'I', 'I', 'Y', 'F', 'N', 'Y']\n",
      "Cell 5 in column 'Prologue Text': ['H', 'I', 'W', 'W', 'J', 'T', 'T', 'A', 'W', 'W', 'T', 'U', 'B', 'W', 'S', 'T', 'W', 'W', 'W', 'I', 'I', 'O', 'I', 'O', 'W', 'T', 'L', 'W', 'T', 'T']\n",
      "Cell 6 in column 'Prologue Text': ['W', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'W', 'I', 'I', 'I', 'R', 'I', 'I', 'L', 'W', 'A', 'W', 'A', 'I', 'I', 'I', 'I', 'I', 'T', 'I', 'M', 'T', 'M', 'M', 'I', 'I', 'I', 'I', 'T', 'I', 'C', 'J', 'W', 'T', 'L']\n",
      "Cell 7 in column 'Prologue Text': ['I', 'V', 'S', 'A', 'B', 'T', 'H', 'T', 'A', 'A', 'A', 'H', 'A', 'P', 'I', 'I', 'I', 'I', 'I', 'A', 'A', 'A', 'L', 'H', 'L', 'M', 'D', 'G', 'A', 'A', 'S', 'T', 'S', 'M', 'F', 'G', 'S', 'I', 'P', 'I', 'N']\n",
      "Cell 8 in column 'Prologue Text': ['T', 'T', 'W', 'I', 'I', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'S', 'I', 'A', 'I', 'A', 'D', 'J', 'A', 'W', 'B', 'J', 'V', 'W', 'B', 'I', 'T', 'T', 'D', 'H', 'T', 'T', 'T', 'O', 'M', 'I', 'Y', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'A']\n",
      "Cell 9 in column 'Prologue Text': ['W', 'I', 'T', 'A', 'T', 'Y', 'M', 'S', 'A', 'T', 'A', 'S', 'I', 'O', 'T', 'S', 'T', 'A', 'T', 'T', 'W', 'W', 'M', 'L', 'A', 'O', 'T', 'S', 'M', 'S', 'O', 'W', 'B', 'Y', 'Y', 'M', 'Y', 'W', 'S', 'W', 'F', 'W', 'W', 'W', 'T', 'T', 'F', 'H', 'S', 'M', 'T']\n"
     ]
    }
   ],
   "source": [
    "# Function to find capital letters in a string\n",
    "def find_capital_letters(text):\n",
    "    return [char for char in text if char.isupper()]\n",
    "\n",
    "capital_letters_per_cell = []\n",
    "\n",
    "# Specify the column name you want to search\n",
    "column_name = 'Prologue Text'  # Replace with the actual column name\n",
    "\n",
    "# Check if the column exists in the DataFrame\n",
    "if column_name not in df.columns:\n",
    "    print(f\"Column '{column_name}' does not exist in the DataFrame.\")\n",
    "else:\n",
    "    # Apply the function to the column to find capital letters in each cell\n",
    "    capital_letters_per_cell = df[column_name].apply(find_capital_letters)\n",
    "\n",
    "    # Print the capital letters found in each cell of the specified column\n",
    "    for i, letters in enumerate(capital_letters_per_cell):\n",
    "        print(f\"Cell {i+1} in column '{column_name}': {letters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20fbad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/Vero/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "# Download the words corpus if not already downloaded\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of lists of letters\n",
    "letter_lists = [\n",
    "    ['T', 'F', 'I', 'I', 'T', 'F', 'I', 'T', 'F', 'L', 'T', 'F', 'F', 'F', 'I', 'F', 'I', 'A', 'I', 'I', 'N', 'O', 'T', 'I', 'I', 'L', 'T', 'T', 'B', 'Y', 'T', 'I', 'B', 'I'],\n",
    "    ['S', 'I', 'I', 'S', 'I', 'R', 'I', 'S', 'B', 'I', 'I', 'W', 'I', 'W', 'I', 'W', 'T', 'I', 'T', 'E', 'I', 'T', 'I', 'D', 'T', 'I', 'T', 'T', 'I', 'T', 'T', 'T', 'I', 'W', 'I', 'W', 'M', 'B', 'I', 'S', 'O', 'S', 'I', 'I', 'T', 'T', 'B', 'I', 'I', 'L', 'T', 'P', 'S', 'T'],\n",
    "    # ... (add other lists here)\n",
    "]\n",
    "\n",
    "# Function to check if a word is valid English\n",
    "def is_english_word(word):\n",
    "    return word.lower() in words.words()\n",
    "\n",
    "# Function to find English words from a list of letters\n",
    "def find_english_words(letter_list):\n",
    "    found_words = set()\n",
    "    # Generate all permutations of the letters\n",
    "    for r in range(1, len(letter_list) + 1):  # +1 to include the full length of the list\n",
    "        for perm in itertools.permutations(letter_list, r):\n",
    "            word = ''.join(perm).lower()\n",
    "            if is_english_word(word):\n",
    "                found_words.add(word)\n",
    "    return found_words\n",
    "\n",
    "# Find English words for each list of letters\n",
    "for i, letter_list in enumerate(letter_lists, start=1):\n",
    "    english_words = find_english_words(letter_list)\n",
    "    print(f\"Cell {i} in column 'Prologue Text': {english_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ceb063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = ''.join(c for c in text if c not in punctuation)\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Join the words back into a string\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88aea4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function to the text column\n",
    "df['Prologue Text'] = df['Prologue Text'].apply(preprocess_text)\n",
    "\n",
    "# Calculate word count\n",
    "df['Word Count'] = df['Prologue Text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Calculate average sentence length\n",
    "df['Avg Sentence Length'] = df['Prologue Text'].apply(lambda x: len(sent_tokenize(x)) if len(sent_tokenize(x))>0 else 0)\n",
    "\n",
    "# Calculate average word length\n",
    "df['Avg Word Length'] = df['Prologue Text'].apply(lambda x: sum(len(word) for word in str(x).split()) / len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a51dd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Prologue Text</th>\n",
       "      <th>Date released</th>\n",
       "      <th>Color</th>\n",
       "      <th>Total Album Sales (In Millions)</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Avg Sentence Length</th>\n",
       "      <th>Avg Word Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fearless</td>\n",
       "      <td>album called fearless guess id like clarify ch...</td>\n",
       "      <td>11/08/2008</td>\n",
       "      <td>gold</td>\n",
       "      <td>10,002,500</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>5.902256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Speak Now</td>\n",
       "      <td>speak forever hold peace words said preachers ...</td>\n",
       "      <td>10/25/2011</td>\n",
       "      <td>purple</td>\n",
       "      <td>6,437,500</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>5.134921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red</td>\n",
       "      <td>theres old poem neruda ive always captivated o...</td>\n",
       "      <td>10/22/2012</td>\n",
       "      <td>red</td>\n",
       "      <td>7,257,500</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>5.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989</td>\n",
       "      <td>songs life born reading pennsylvania december ...</td>\n",
       "      <td>10/27/2014</td>\n",
       "      <td>light blue</td>\n",
       "      <td>10,735,000</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>5.390041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reputation</td>\n",
       "      <td>heres something ive learned people think know ...</td>\n",
       "      <td>11/10/2017</td>\n",
       "      <td>black</td>\n",
       "      <td>3,710,000</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>6.120332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lover</td>\n",
       "      <td>found old diaries childhood teens covered dust...</td>\n",
       "      <td>08/23/2019</td>\n",
       "      <td>pink</td>\n",
       "      <td>2,722,500</td>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>5.837662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Folklore</td>\n",
       "      <td>started imagery visuals popped mind piqued cur...</td>\n",
       "      <td>07/24/2020</td>\n",
       "      <td>grey</td>\n",
       "      <td>3,197,500</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>6.125654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Evermore</td>\n",
       "      <td>put plainly couldnt stop writing songs try put...</td>\n",
       "      <td>12/11/2020</td>\n",
       "      <td>brown</td>\n",
       "      <td>1,867,500</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>5.871245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>keeps night momentary glimmer distraction tini...</td>\n",
       "      <td>10/21/2022</td>\n",
       "      <td>dark blue</td>\n",
       "      <td>3,700,000</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>5.894737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Album Name                                      Prologue Text  \\\n",
       "0    Fearless  album called fearless guess id like clarify ch...   \n",
       "1   Speak Now  speak forever hold peace words said preachers ...   \n",
       "2         Red  theres old poem neruda ive always captivated o...   \n",
       "3        1989  songs life born reading pennsylvania december ...   \n",
       "4  Reputation  heres something ive learned people think know ...   \n",
       "5       Lover  found old diaries childhood teens covered dust...   \n",
       "6    Folklore  started imagery visuals popped mind piqued cur...   \n",
       "7    Evermore  put plainly couldnt stop writing songs try put...   \n",
       "8   Midnights  keeps night momentary glimmer distraction tini...   \n",
       "\n",
       "  Date released       Color Total Album Sales (In Millions)  Word Count  \\\n",
       "0    11/08/2008        gold                      10,002,500         133   \n",
       "1    10/25/2011      purple                       6,437,500         252   \n",
       "2    10/22/2012         red                       7,257,500         171   \n",
       "3    10/27/2014  light blue                      10,735,000         241   \n",
       "4    11/10/2017       black                       3,710,000         241   \n",
       "5    08/23/2019        pink                       2,722,500         308   \n",
       "6    07/24/2020        grey                       3,197,500         191   \n",
       "7    12/11/2020       brown                       1,867,500         233   \n",
       "8    10/21/2022  dark blue                        3,700,000         285   \n",
       "\n",
       "   Avg Sentence Length  Avg Word Length  \n",
       "0                    1         5.902256  \n",
       "1                    1         5.134921  \n",
       "2                    1         5.614035  \n",
       "3                    1         5.390041  \n",
       "4                    1         6.120332  \n",
       "5                    1         5.837662  \n",
       "6                    1         6.125654  \n",
       "7                    1         5.871245  \n",
       "8                    1         5.894737  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc6959e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed data to a new CSV file\n",
    "df.to_csv('preprocessed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
